# syntax=v1

def vllm():
    install.conda()
    install.python()
    install.apt_packages(name=["git", "build-essential"])
    install.python_packages(name=[
        "torch",
        "sentencepiece", 
        "transformers", 
        "autoawq",
        "xformers",
        "fschat", 
        "accelerate", 
        "ray", 
        "pandas", 
        "numpy", 
        "huggingface_hub", 
        "ninja", 
        "psutil", 
        "pyarrow", 
        "fastapi", 
        "uvicorn[standard]", 
        "'pydantic<2'", 
        # pip vllm only support nvidia toolkit 11.8, 不支持12.X驱动，
        # "vllm"
        ])
    # must run on gpu
    # install.python_packages(name=["git+https://github.com/vllm-project/vllm.git"])

    # can run on cpu
    run(commands=["git clone https://github.com/vllm-project/vllm.git"])

def build():
    # this comes with dev tools
    base(image="nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04", dev=True)
    shell("zsh")
    vllm()

def serve():
    base(image="nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04")
    vllm()
